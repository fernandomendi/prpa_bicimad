{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5885446-b6c9-4608-8ec8-faafb11d06e8",
   "metadata": {},
   "source": [
    "## **Práctica BiciMAD**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89329972-ac32-4e29-be32-07cc51fd0054",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3df232-fae1-453f-b941-3f77fa4417ad",
   "metadata": {},
   "source": [
    "El objetivo de esta práctica es, data una muestra de datos de BiciMAD, obtener utilizando pyspark la localización de una posible nueva parada, en función del tráfico de la zona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501b68a-8f66-4a84-8823-c01f8a8c79fc",
   "metadata": {},
   "source": [
    "### Datos usados y forma de obtener el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38568ed-c237-4293-9790-6e61b53e4992",
   "metadata": {},
   "source": [
    "Los datos que tomaremos serán los datos proporcionados por la página web de BiciMAD, https://opendata.emtmadrid.es/Datos-estaticos/Datos-generales-(1)\n",
    "Utilizaremos los archivos correspondientes a junio del 2021, tanto de la situación de las estaciones bicimad como del uso. \n",
    "Para el correcto funcionamiento de la práctica, es necesario tener estos dos archivos en una carpeta llamada data donde estemos trabajando.\n",
    "\n",
    "Para ejecutar el programa no es necesario nada más, simplemente ejecutarlo en terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2d544-a043-4d00-a433-b040c6ff8b25",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "859b44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import acos, cos, radians, sin\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f10685b-30c3-40b8-931e-d78634450c86",
   "metadata": {},
   "source": [
    "#### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83d70a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_sphere(pt1, pt2): # Devuelve la distancia en km entre dos puntos dadas sus coordenadas (esféricas)\n",
    "    pt1 = tuple(map(radians, pt1))\n",
    "    pt2 = tuple(map(radians, pt2))\n",
    "    x = sin(pt1[0]) * sin(pt2[0]) + cos(pt1[0]) * cos(pt2[0]) * cos(pt1[1] - pt2[1])\n",
    "    if x > 1: # redondeamos el error para no salirnos del dominio del arccos\n",
    "        x = 1\n",
    "    return 6371 * (acos(x))\n",
    "\n",
    "def get_stop_trafic(spark: SparkSession, filename): # Devuelve un df con el tráfico de cada parada\n",
    "    movements_df = spark.read.json(filename)\n",
    "    plug_count = movements_df.\\\n",
    "        withColumnRenamed(\"idplug_station\", \"id\").\\\n",
    "        groupBy(\"id\").\\\n",
    "        count().\\\n",
    "        withColumnRenamed(\"count\", \"plug_count\")\n",
    "    unplug_count = movements_df.\\\n",
    "        withColumnRenamed(\"idunplug_station\", \"id\").\\\n",
    "        groupBy(\"id\").\\\n",
    "        count().\\\n",
    "        withColumnRenamed(\"count\", \"unplug_count\")\n",
    "    trafic_df = plug_count.\\\n",
    "        join(unplug_count, on=[\"id\"], how=\"left_outer\").\\\n",
    "        sort(\"id\").\\\n",
    "        withColumn(\"trafic\", col(\"plug_count\")+col(\"unplug_count\")).\\\n",
    "        select(col(\"id\"), col(\"trafic\"))\n",
    "    return trafic_df\n",
    "\n",
    "def get_stops(spark: SparkSession, month_ref): #Devuelve un df con la posición y tráfico de cada parada\n",
    "    df = spark.read.json(f\"data/{month_ref}_stations.json\")\n",
    "    stations_df = spark.\\\n",
    "        createDataFrame(df.first()[\"stations\"]).\\\n",
    "        select(col(\"id\"), col(\"latitude\").cast(\"float\"), col(\"longitude\").cast(\"float\"))\n",
    "    trafic_df = get_stop_trafic(spark, f\"data/{month_ref}_movements.json\")\n",
    "    stops_df = stations_df.join(trafic_df, on=[\"id\"], how=\"left_outer\")\n",
    "    return stops_df\n",
    "\n",
    "def get_learning_df(df): # Genera el df de entrada del modelo de ML\n",
    "    df = np.array(df.where(col(\"trafic\").isNotNull()).collect())\n",
    "    learning = []\n",
    "    for i in df:\n",
    "        row = n_closest_stops(df, (i[1], i[2]))\n",
    "        row.append(i[3])\n",
    "        row.insert(0, i[2])\n",
    "        row.insert(0, i[1])\n",
    "        learning.append(row)\n",
    "    return spark.createDataFrame(pd.DataFrame(learning), schema=[\"lat\", \"lon\", \"dist*trafic1\", \"dist*trafic2\", \"dist*trafic3\", \"trafic\"])\n",
    "    \n",
    "def n_closest_stops(df, pt, n=3): #Devuelve las n paradas que minimizan la distancia por el tráfico a cierto punto (pt) \n",
    "    df2 = np.copy(df)\n",
    "    dists = lambda stop: [distance_sphere(pt, [stop[1], stop[2]]) * stop[3]]\n",
    "    d = np.array([dists(i) for i in df2])\n",
    "    d = d[d[:,0].argsort()]\n",
    "    return d[1:n+1,:].flatten().tolist()\n",
    "    \n",
    "def get_min_max_lat_lon(df):\n",
    "    min_lat = df.agg({\"latitude\":\"min\"}).head()[\"min(latitude)\"]\n",
    "    max_lat = df.agg({\"latitude\":\"max\"}).head()[\"max(latitude)\"]\n",
    "    min_lon = df.agg({\"longitude\":\"min\"}).head()[\"min(longitude)\"]\n",
    "    max_lon = df.agg({\"longitude\":\"max\"}).head()[\"max(longitude)\"]\n",
    "    return min_lat, max_lat, min_lon, max_lon\n",
    "\n",
    "def pt_in_hull(pt, hull, eps=10**(-4)): # Evalúa si un punto está en el área de servicio de BiciMad\n",
    "    return all((np.dot(eq[:-1], pt) + eq[-1] <= eps) for eq in hull.equations)\n",
    "\n",
    "def generate_points(sc: SparkContext, n, df): # mins_maxs = (min_lat, max_lat, min_lon, max_lon)\n",
    "    pts = []\n",
    "    i = 0\n",
    "    hull = ConvexHull(np.array(df.select(col(\"latitude\"), col(\"longitude\")).collect()))\n",
    "    min_lat, max_lat, min_lon, max_lon = get_min_max_lat_lon(df)\n",
    "    while i < n:\n",
    "        pt = (random.uniform(min_lat, max_lat), random.uniform(min_lon, max_lon))\n",
    "        if pt_in_hull(pt, hull) and pt not in pts:   #Consideramos que estén en el área de servicio de BiciMAD\n",
    "            pts.append(pt)\n",
    "            i += 1\n",
    "    return sc.parallelize(pts)\n",
    "\n",
    "def get_mesh(sc: SparkContext, n, df): # Genera un df con los puntos a evaluar\n",
    "    pts = np.array(generate_points(sc, n, df).collect())\n",
    "    df_ = np.array(df.where(col(\"trafic\").isNotNull()).collect())\n",
    "    testing = []\n",
    "    for pt in pts:\n",
    "        row = n_closest_stops(df_, pt)\n",
    "        row.insert(0, pt[1])\n",
    "        row.insert(0, pt[0])\n",
    "        testing.append(row)\n",
    "    return spark.createDataFrame(pd.DataFrame(testing), schema=[\"lat\", \"lon\", \"dist*trafic1\", \"dist*trafic2\", \"dist*trafic3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64257dd-13f3-48d7-a013-4160f6db1f7b",
   "metadata": {},
   "source": [
    "#### EJECUCIÓN DEL PROGRAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d882a90f-46e1-4444-9317-b7f6ff49b7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Comenzamos la sesión de spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af669e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5ab07-94d3-4dbd-8201-f6f382d0fa28",
   "metadata": {},
   "source": [
    "Creamos las paradas del dataset con sus coordenadas y su tráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92974660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+------+\n",
      "| id| latitude| longitude|trafic|\n",
      "+---+---------+----------+------+\n",
      "|  1|40.417213|-3.7018342|  3798|\n",
      "|  2|40.417313| -3.701603|  1708|\n",
      "|  3| 40.42059|-3.7058415|  3390|\n",
      "|  4|40.430294| -3.706917|  3159|\n",
      "|  5| 40.42855|-3.7025876|  2258|\n",
      "|  6| 40.42852|  -3.70205|  4398|\n",
      "|  7| 40.42415| -3.698447|  3525|\n",
      "|  8| 40.42519|-3.6977715|  3530|\n",
      "|  9|40.427868|-3.6954403|  6043|\n",
      "| 10|40.415607|-3.7095084|  3585|\n",
      "| 11| 40.42533|  -3.69214|  1946|\n",
      "| 12| 40.42695|-3.7035918|  3200|\n",
      "| 13|40.428425|-3.7061932|  6230|\n",
      "| 14|40.427326|-3.7104416|  3294|\n",
      "| 15|40.426094| -3.713479|  4524|\n",
      "| 16| 40.42624|-3.7074454|  3438|\n",
      "| 17|40.423073|-3.7075064|  5069|\n",
      "| 18|40.423264|-3.7038312|  3207|\n",
      "| 19|40.420776|-3.6996503|  5370|\n",
      "| 20| 40.42186|-3.6954982|  2867|\n",
      "+---+---------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stops_df = get_stops(spark, \"202106\")\n",
    "stops_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cff00a9-0069-4899-b285-d578f4e37553",
   "metadata": {},
   "source": [
    "Creamos el modelo de ml que aplicaremos a los datos existentes (paradas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60345def",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_df = get_learning_df(stops_df)\n",
    "feature_assembler = VectorAssembler(inputCols=[\"lat\", \"lon\", \"dist*trafic1\", \"dist*trafic2\", \"dist*trafic3\"], \n",
    "                                    outputCol=\"features\")\n",
    "output = feature_assembler.transform(learning_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7793a99-356b-4846-89ba-44f5181eaec0",
   "metadata": {},
   "source": [
    "Entrenamos el modelo anterior. Una vez hecho esto, comprobamos su eficiencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a973d95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+------+------------------+\n",
      "|            features|               lat|                lon|trafic|        prediction|\n",
      "+--------------------+------------------+-------------------+------+------------------+\n",
      "|[40.4202842712402...|40.420284271240234|-3.7081246376037598|5446.0|3667.7234927832615|\n",
      "|[40.4229621887207...|  40.4229621887207| -3.655555248260498|1915.0|2474.4316554000834|\n",
      "|[40.42919921875,-...|    40.42919921875| -3.696716785430908|3021.0| 3402.851403490524|\n",
      "|[40.4334068298339...|40.433406829833984| -3.687915325164795|2452.0| 2607.692019357113|\n",
      "|[40.4343338012695...| 40.43433380126953|-3.6835832595825195|3203.0|2774.2197304078145|\n",
      "|[40.4371490478515...| 40.43714904785156|-3.6483585834503174|1642.0|1691.4386677766452|\n",
      "|[40.4383697509765...| 40.43836975097656|  -3.69281005859375|2040.0|2564.3695159368217|\n",
      "|[40.4431495666503...| 40.44314956665039| -3.657409906387329| 939.0|1624.8590102716116|\n",
      "|[40.3972625732421...| 40.39726257324219| -3.694502592086792|3746.0|4017.3563881003065|\n",
      "|[40.4007797241210...|40.400779724121094|-3.6882407665252686|2987.0| 2933.198313472327|\n",
      "|[40.4053153991699...| 40.40531539916992|-3.7071259021759033|4465.0|  4140.10382752039|\n",
      "|[40.4181518554687...| 40.41815185546875| -3.698436737060547|3152.0|3499.7952775519807|\n",
      "|[40.4372482299804...| 40.43724822998047|  -3.67722225189209|3317.0|2385.7381087890826|\n",
      "|[40.4463500976562...| 40.44635009765625|  -3.71382999420166|2513.0| 2819.195887167356|\n",
      "|[40.4463653564453...| 40.44636535644531| -3.703667402267456|6042.0|2987.8493923842907|\n",
      "|[40.3979721069335...|40.397972106933594| -3.669250011444092|3843.0| 3608.151321130106|\n",
      "|[40.4491195678710...|40.449119567871094|-3.7273099422454834|1650.0| 3409.761591241928|\n",
      "|[40.4630279541015...| 40.46302795410156| -3.697333335876465|2375.0|2402.3840002969373|\n",
      "|[40.3990135192871...| 40.39901351928711|-3.6607768535614014|1707.0|2154.2032626705477|\n",
      "|[40.4010009765625...|  40.4010009765625|-3.7043612003326416|3422.0| 4441.646865399787|\n",
      "+--------------------+------------------+-------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.10296743380261353\n"
     ]
    }
   ],
   "source": [
    "final_data = output.select([\"features\", \"lat\", \"lon\", \"trafic\"])\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"trafic\",\n",
    "                      maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_predictions.show()\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"trafic\", metricName=\"r2\")\n",
    "print(f\"R Squared (R2) on test data = {lr_evaluator.evaluate(lr_predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618176ce-8a1b-4819-8580-f1819b268ea0",
   "metadata": {},
   "source": [
    "Por último, evaluamos el modelo en una malla de 10000 puntos tomados de forma aleatoria dentro del área de servicio de BiciMAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98238a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------------+------------------+\n",
      "|            features|               lat|                lon|        prediction|\n",
      "+--------------------+------------------+-------------------+------------------+\n",
      "|[40.4035542630039...|40.403554263003905|-3.6937027740367383| 3616.657010823721|\n",
      "|[40.4425364546863...| 40.44253645468634|-3.6806904698107186|2432.6586004258133|\n",
      "|[40.4227744211040...| 40.42277442110405| -3.687217047982983| 3080.013405438978|\n",
      "|[40.4440461526848...| 40.44404615268481|-3.6913689459366115|2666.2335425653728|\n",
      "|[40.4542414824484...| 40.45424148244843|-3.7075525052614164|2984.3463198402897|\n",
      "|[40.4227035425698...|40.422703542569806|-3.6795825056585776|  2515.83129288035|\n",
      "|[40.4295104495267...| 40.42951044952676| -3.714135469234338| 3621.964012391516|\n",
      "|[40.4010887084651...| 40.40108870846514|-3.6679126612089394|3240.0038968678564|\n",
      "|[40.4436270297437...| 40.44362702974379|-3.6795720710359174|2222.1693609067006|\n",
      "|[40.4496710901472...| 40.44967109014725| -3.674719372442287|2062.7895467204507|\n",
      "|[40.4753435935555...|40.475343593555515| -3.696004578647173|1984.7555364059517|\n",
      "|[40.4067212179397...| 40.40672121793974| -3.691741521839176|3674.9650054509984|\n",
      "|[40.4018494204551...|40.401849420455115|-3.6783071045434714|3511.5545965812635|\n",
      "|[40.4376161996703...| 40.43761619967035|-3.6719043281982113|2411.6402665612986|\n",
      "|[40.3979962584267...|40.397996258426716|-3.6611112616818198|2347.6256779293763|\n",
      "|[40.4540241080735...| 40.45402410807354| -3.722808341417745| 3171.981459237286|\n",
      "|[40.4562659691489...| 40.45626596914894|-3.7093616989643947|2704.9612511902815|\n",
      "|[40.4662518838902...| 40.46625188389024|-3.6906198902208254|1897.6459335213294|\n",
      "|[40.4098453822853...| 40.40984538228537|-3.7222607252041384| 4807.102631379385|\n",
      "|[40.4270520957706...| 40.42705209577068| -3.722236820720708|4040.8371037967736|\n",
      "+--------------------+------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mesh = get_mesh(sc, 10**5, stops_df)\n",
    "mesh_test = feature_assembler.transform(mesh).select([\"features\", \"lat\", \"lon\"])\n",
    "mesh_predictions = lr_model.transform(mesh_test)\n",
    "mesh_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6b65e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un punto candidato a poner una nueva parada de Bicimad es (40.40191282516034, -3.7204495853564508) puesto que se estima que tenga un total de 5150.759971562773 usos al mes\n"
     ]
    }
   ],
   "source": [
    "max_trafic_pred = mesh_predictions.agg({\"prediction\": \"max\"}).head()[0]\n",
    "best_row = mesh_predictions.filter(col(\"prediction\") == max_trafic_pred).head()\n",
    "print(f\"Un punto candidato a poner una nueva parada de Bicimad es ({best_row['lat']}, {best_row['lon']}) puesto que se estima que tenga un total de {best_row['prediction']} usos al mes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae00c4b-95a2-405d-a326-17141bd3f0ac",
   "metadata": {},
   "source": [
    "#### RESULTADOS Y CONCLUSIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b63dd-0df8-46f0-b24a-1d9cd2eecd5d",
   "metadata": {},
   "source": [
    "Podemos observar que el punto devuelto por el programa se sitúa cerca del antiguo estadio Vicente Calderón. Ha ayudado mucho haber cursado la asignatura de Programación Declarativa puesto que la principal forma de trabajar con las estructuras de datos de pyspark es el orden superior. La práctica también nos ha permitido adentrarnos en el mundo del machine learning, algo muy presente hoy en día, y que nos será útil en un futuro. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
